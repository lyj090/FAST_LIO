\section{Problem Definition and System Modeling}
\label{sec:modeling}

This section provides a formal description of the LiDAR-inertial system, including the state vector, inputs, observations, noise characteristics, and the discrete-time state-space model used for estimation.

\subsection{System Description}
\label{subsec:system_description}

The task is real-time 6-DoF pose estimation of a mobile robot (e.g., UAV or ground vehicle) using a tightly coupled LiDAR-IMU sensor suite. The system components are defined as follows:

\begin{itemize}
    \item \textbf{State vector $\mathbf{x}_k$}: The full state of the IMU in the global frame $G$ (i.e., the first IMU frame) includes:
    \begin{itemize}
        \item Position ${}^G\mathbf{p}_I \in \mathbb{R}^3$;
        \item Orientation ${}^G\mathbf{R}_I \in SO(3)$;
        \item Velocity ${}^G\mathbf{v}_I \in \mathbb{R}^3$;
        \item IMU bias terms: gyroscope bias $\mathbf{b}_{\boldsymbol{\omega}} \in \mathbb{R}^3$, accelerometer bias $\mathbf{b}_{\mathbf{a}} \in \mathbb{R}^3$;
        \item Gravity vector ${}^G\mathbf{g} \in \mathbb{R}^3$ (estimated online for robustness in non-level environments).
    \end{itemize}
    The total state dimension is 18:
    \begin{equation}
        \mathbf{x} = \left[ {}^G\mathbf{R}_I^T, {}^G\mathbf{p}_I^T, {}^G\mathbf{v}_I^T, \mathbf{b}_{\boldsymbol{\omega}}^T, \mathbf{b}_{\mathbf{a}}^T, {}^G\mathbf{g}^T \right]^T.
    \end{equation}

    \item \textbf{Input $\mathbf{u}_k$}: Raw IMU measurements at time $k$:
    \begin{itemize}
        \item Angular velocity: $\boldsymbol{\omega}_m = \boldsymbol{\omega}_I + \mathbf{b}_{\boldsymbol{\omega}} + \mathbf{n}_{\boldsymbol{\omega}}$;
        \item Specific force: $\mathbf{a}_m = \mathbf{a}_I + \mathbf{b}_{\mathbf{a}} + \mathbf{n}_{\mathbf{a}}$,
    \end{itemize}
    where $\mathbf{n}_{\boldsymbol{\omega}}$ and $\mathbf{n}_{\mathbf{a}}$ are zero-mean Gaussian white noises, $\mathbf{n}_{\mathbf{b}_\mathbf{a}}$ and $\mathbf{n}_{\mathbf{b}_{\boldsymbol{\omega}}}$ are zero-mean Gaussian noises of the IMU bias.

    \item \textbf{Observation}: The residual will be constructed from a set of geometric feature points (planes or edges) extracted from a LiDAR scan.

    \item \textbf{Sources of uncertainty}:
    \begin{itemize}
        \item \textit{Process noise}: IMU measurement noise ($\mathbf{n}_{\boldsymbol{\omega}}, \mathbf{n}_{\mathbf{a}}$) and random-walk bias drift ($\mathbf{n}_{\mathbf{b}_{\boldsymbol{\omega}}}, \mathbf{n}_{\mathbf{b}_\mathbf{a}}$);
        \item \textit{Measurement noise}: Geometric noise $\mathbf{n}_{f_j}$ in LiDAR point positions;
        \item \textit{Modeling errors}: Unmodeled dynamics, calibration inaccuracies, and feature extraction errors.
    \end{itemize}
\end{itemize}

\subsection{State-Space Model}
\label{subsec:state_space_model}

The system dynamics are first modeled in a continuous manner and then discretized.

Let $\mathcal{M}$ be the manifold of dimension $n$ in consideration (e.g., $\mathcal{M} = SO(3)$). Since manifolds are locally homeomorphic to $\mathbb{R}^n$, we can establish a bijective mapping from a local neighborhood on $\mathcal{M}$ to its tangent space $\mathbb{R}^n$ via two encapsulation operators $\boxplus$ and $\boxminus$\cite{calculate_def}:

\begin{align*}
    \boxplus &: \mathcal{M} \times \mathbb{R}^n \to \mathcal{M}; &
    \boxminus : \mathcal{M} \times \mathcal{M} \to \mathbb{R}^n \\
    \mathcal{M} = SO(3): & \quad \mathbf{R} \boxplus \mathbf{r} = \mathbf{R} \mathrm{Exp}(\mathbf{r}); &
    \mathbf{R}_1 \boxminus \mathbf{R}_2 = \mathrm{Log}(\mathbf{R}_2^T \mathbf{R}_1) \\
    \mathcal{M} = \mathbb{R}^n: & \quad \mathbf{a} \boxplus \mathbf{b} = \mathbf{a} + \mathbf{b}; &
    \mathbf{a} \boxminus \mathbf{b} = \mathbf{a} - \mathbf{b}
\end{align*}
where $\mathrm{Exp}(\mathbf{r}) = \mathbf{I} + \frac{\mathbf{r}}{\|\mathbf{r}\|} \sin(\|\mathbf{r}\|) + \frac{\mathbf{r}^2}{\|\mathbf{r}\|^2} (1 - \cos(\|\mathbf{r}\|))$ is the exponential map\cite{calculate_def}, and $\mathrm{Log}(\cdot)$ is its inverse map.

For a compound manifold $\mathcal{M} = SO(3) \times \mathbb{R}^n$ we have
\begin{equation*}
    \begin{bmatrix} \mathbf{R} \\ \mathbf{a} \end{bmatrix} \boxplus \begin{bmatrix} \mathbf{r} \\ \mathbf{b} \end{bmatrix} = \begin{bmatrix} \mathbf{R} \boxplus \mathbf{r} \\ \mathbf{a} + \mathbf{b} \end{bmatrix}; \quad
    \begin{bmatrix} \mathbf{R}_1 \\ \mathbf{a} \end{bmatrix} \boxminus \begin{bmatrix} \mathbf{R}_2 \\ \mathbf{b} \end{bmatrix} = \begin{bmatrix} \mathbf{R}_1 \boxminus \mathbf{R}_2 \\ \mathbf{a} - \mathbf{b} \end{bmatrix}.
\end{equation*}

From the above definition, it is easy to verify that:
\begin{equation*}
    (\mathbf{x} \boxplus \mathbf{u}) \boxminus \mathbf{x} = \mathbf{u}; \quad \mathbf{x} \boxplus (\mathbf{y} \boxminus \mathbf{x}) = \mathbf{y}; \quad \forall \mathbf{x}, \mathbf{y} \in \mathcal{M}, \; \forall \mathbf{u} \in \mathbb{R}^n.
\end{equation*}

\subsubsection{Continuous-Time Dynamics}

Assuming an IMU is rigidly attached to the LiDAR with a known extrinsic ${}^{I}\mathbf{T}_{L} = ({}^{I}\mathbf{R}_{L}, {}^{I}\mathbf{p}_{L})$. Taking the IMU frame (denoted as $I$) as the body frame of reference leads to a kinematic model:
\begin{subequations}
    \begin{align}
        {}^G\dot{\mathbf{p}}_I &= {}^G\mathbf{v}_I, \\
        {}^G\dot{\mathbf{v}}_I &= {}^G\mathbf{R}_I (\mathbf{a}_m - \mathbf{b}_{\mathbf{a}} - \mathbf{n}_{\mathbf{a}}) + {}^G\mathbf{g}, \\
        {}^G\dot{\mathbf{R}}_I &= {}^G\mathbf{R}_I \lfloor\boldsymbol{\omega}_m - \mathbf{b}_{\boldsymbol{\omega}} - \mathbf{n}_{\boldsymbol{\omega}}\rfloor_\wedge, \label{rotation_dyn}\\
        \dot{\mathbf{b}}_{\boldsymbol{\omega}} &= \mathbf{n}_{\mathbf{b}_{\boldsymbol{\omega}}}, \quad
        \dot{\mathbf{b}}_a = \mathbf{n}_{\mathbf{b}_\mathbf{a}}, \quad
        {}^G\dot{\mathbf{g}} = \mathbf{0}.
    \end{align}
\label{eq:continuous_dynamics}%
\end{subequations}
where the notation $\lfloor\mathbf{a}\rfloor_\wedge$ denotes the skew-symmetric matrix of vector $\mathbf{a} \in \mathbb{R}^3$ that maps the cross product operation. The derivation of \eqref{rotation_dyn} is shown in the Appendix \ref{appendix: rotation}.

\subsubsection{Discrete Model}
Based on the $\boxplus$ operation defined above, we can discretize the continuous model in \eqref{eq:continuous_dynamics} at the IMU sampling period $\Delta t$ using a zero-order holder. The resultant discrete model is:
\begin{equation}
    \mathbf{x}_{i+1} = \mathbf{x}_i \boxplus (\Delta t \mathbf{f}(\mathbf{x}_i, \mathbf{u}_i, \mathbf{w}_i)),
    \label{eq:discrete_state}
\end{equation}
where $i$ is the index of IMU measurements, the function $\mathbf{f}$, state $\mathbf{x}$, input $\mathbf{u}$ and noise $\mathbf{w}$ are defined as below:

\begin{equation}
    \begin{split}
    \mathcal{M} &= SO(3) \times \mathbb{R}^{15}, \quad \dim(\mathcal{M}) = 18 \\
    \mathbf{x} &\doteq \begin{bmatrix} {}^G\mathbf{R}_I^T & {}^G\mathbf{p}_I^T & {}^G\mathbf{v}_I^T & \mathbf{b}_{\boldsymbol{\omega}}^T & \mathbf{b}_{\mathbf{a}}^T & {}^G\mathbf{g}^T \end{bmatrix}^T \in \mathcal{M} \\
    \mathbf{u} &\doteq \begin{bmatrix} \boldsymbol{\omega}_m^T & \mathbf{a}_m^T \end{bmatrix}^T, \quad
    \mathbf{w} \doteq \begin{bmatrix}  \mathbf{n}_{\boldsymbol{\omega}}^T & \mathbf{n}_{\mathbf{a}}^T & \mathbf{n}_{\mathbf{b}_{\boldsymbol{\omega}}}^T & \mathbf{n}_{\mathbf{b}_\mathbf{a}}^T \end{bmatrix}^T \\
    \mathbf{f}(\mathbf{x}_i, \mathbf{u}_i, \mathbf{w}_i) &= 
    \begin{bmatrix}
        \boldsymbol{\omega}_{m_i} - \mathbf{b}_{{\boldsymbol{\omega}}_i} - \mathbf{n}_{{\boldsymbol{\omega}}_i} \\
        {}^G\mathbf{v}_{I_i} \\ 
        {}^G\mathbf{R}_{I_i} (\mathbf{a}_{m_i} - \mathbf{b}_{\mathbf{a}_i} - \mathbf{n}_{\mathbf{a}_i}) + {}^G\mathbf{g}_i \\
        \mathbf{n}_{\mathbf{b}_{\boldsymbol{\omega}_i}} \\
        \mathbf{n}_{\mathbf{b}_{\mathbf{a}_i}} \\
        \mathbf{0}_{3\times1}
    \end{bmatrix}.
    \label{eq:discrete_dynamics} 
    \end{split}
\end{equation}

\subsection{Measurement Model}

For the $j$-th LiDAR feature point, the residual observation is:
\begin{equation}
    \mathbf{z}_j = h_j(\mathbf{x}_k) + \mathbf{v}_j = \mathbf{G}_j \left( {}^G\hat{\mathbf{p}}_{f_j} - {}^G\mathbf{q}_j \right) + \mathbf{v}_j,
    \label{eq:meas_model}
\end{equation}
where:
\begin{itemize}
    \item ${}^G\hat{\mathbf{p}}_{f_j}$ is the motion-compensated LiDAR point in the global frame (computed via backward propagation);
    \item ${}^G\mathbf{q}_j$ is a reference point on the nearest plane or edge in the map;
    \item $\mathbf{G}_j = 
    \begin{cases}
        \mathbf{u}_j^T & \text{(plane feature)} \\
        [\mathbf{u}_j]_\times & \text{(edge feature)}
    \end{cases}$, with $\mathbf{u}_j$ the normal or direction vector;
    \item $\mathbf{v}_j \sim \mathcal{N}(\mathbf{0}, \mathbf{R}_j)$ is the measurement noise that comes from the raw geometric noise $\mathbf{n}_{f_j}$.
\end{itemize}

\subsection{Noise and Uncertainty Settings}
\label{subsec:noise}

The noise covariances are configured as:

\begin{itemize}
    \item \textbf{Process noise covariance $\mathbf{Q} \in \mathbb{R}^{12 \times 12}$}: Diagonal matrix:
    \[
    \mathbf{Q} = \mathrm{diag}\left(
        \sigma_{{\boldsymbol{\omega}}}^2 \mathbf{I}_3,\,
        \sigma_{\mathbf{a}}^2 \mathbf{I}_3,\,
        \sigma_{\mathbf{b}_{\boldsymbol{\omega}}}^2 \mathbf{I}_3,\,
        \sigma_{\mathbf{b}_\mathbf{a}}^2 \mathbf{I}_3
    \right),
    \]
    where $\sigma_{{\boldsymbol{\omega}}}, \sigma_{\mathbf{a}}, \sigma_{\mathbf{b}_{\boldsymbol{\omega}}}, \sigma_{\mathbf{b}_\mathbf{a}}$ are standard deviations from sensor specs.

    \item \textbf{Measurement noise covariance $\mathbf{R} \in \mathbb{R}^{3m \times 3m}$}: Diagonal (feature points assumed independent):
    \[
    \mathbf{R} = \mathrm{diag}\left( \sigma_{\text{plane}}^2, \dots, \sigma_{\text{edge}}^2, \dots \right).
    \]
\end{itemize}

\subsection{Observability and Identifiability Analysis}
\label{subsec:observability}

The system is \textit{locally observable} under general motion:

\begin{itemize}
    \item IMU provides continuous excitation of position, velocity, and orientation;
    \item LiDAR features offer absolute geometric constraints to resolve scale and orientation;
    \item Online estimation of ${}^G\mathbf{g}$ removes dependence on a priori gravity direction, enhancing robustness in non-horizontal scenarios;
    \item With sufficient non-degenerate features, the observability matrix has full rank.
\end{itemize}

This aligns with the theoretical analysis in \cite{fast_lio}, confirming that the state can be uniquely determined in typical operating conditions.