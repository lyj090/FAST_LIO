\section{Introduction}
\label{sec:introduction}
\subsection{Background}
Simultaneous Localization and Mapping (SLAM) is a fundamental capability for autonomous mobile robots, including unmanned aerial vehicles (UAVs). While visual (inertial) odometry (VO/VIO) offers a lightweight and low-cost solution with rich RGB information, it suffers from several limitations: it lacks direct depth measurements, demands significant computational resources for 3D reconstruction, and is highly sensitive to lighting variations.

LiDAR-based odometry, on the other hand, overcomes these challenges by providing accurate, direct depth measurements that are robust to illumination changes and enable efficient 3D geometric inference. Recent works such as FAST-LIO \cite{fast_lio} and demonstrate that tightly-coupled LiDAR-inertial odometry based on iterated Kalman filtering can achieve fast, robust, and high-precision state estimation, making LiDAR a compelling sensor modality for reliable SLAM in dynamic and real-world environments.

\subsection{Problem Motivation}
Despite the robustness of LiDAR sensing, practical LiDAR-inertial odometry systems encounter three critical challenges that degrade estimation performance:

\begin{enumerate}
    \item \textbf{Feature Degradation in Cluttered Environments}: In unstructured or texture-poor scenes (e.g., long corridors, open fields), LiDAR point clouds lack distinctive geometric features. Thus, the LiDAR-based solution easily degenerates.

    \item \textbf{Motion Distortion in Scanning Process}: A LiDAR scan is not instantaneous; points are sequentially sampled over tens to hundreds of milliseconds. If the platform is in motion during this interval, the resulting point cloud becomes geometrically distorted, which significantly corrupts feature extraction and scan alignment, especially in high-dynamic scenarios.

    \item \textbf{Computational Bottleneck in Tight Fusion}: Tightly-coupled frameworks fuse raw LiDAR feature points (often $m \gg 100$) directly with IMU states. The conventional Kalman gain computation requires inverting a $3m \times 3m$ measurement covariance matrix, an operation with $\mathcal{O}(m^3)$ complexity that quickly becomes infeasible for real-time operation on resource-constrained platforms.
\end{enumerate}

Together, these issues demand an estimation framework that is \textit{robust to feature scarcity}, \textit{immune to motion-induced geometric distortion}, and \textit{computationally efficient} even under dense feature integration.

\subsection{Project Objectives}
To address the above challenges, this project reproduces and analyzes the core estimation pipeline of FAST-LIO, with three tightly aligned technical objectives:

\begin{itemize}
    \item \textbf{Robustness via Tight Coupling}: Replace scan-registration-based loosely-coupled fusion with a \textit{tightly-coupled iterated Kalman filter} that directly fuses raw LiDAR feature points with IMU measurements. This bypasses the need for stable high-level features, thereby mitigating \textit{feature degradation} in cluttered environments.

    \item \textbf{Motion Distortion Compensation}: Implement a formal \textit{backward propagation} mechanism that, using IMU preintegration from the scan-end time, reconstructs the relative pose at each LiDAR pointâ€™s timestamp. This enables precise motion undistortion of the entire scan, resolving the \textit{motion distortion} problem at the measurement level.

    \item \textbf{Efficient Kalman Update}: Based on the \textit{Woodbury matrix identity}, the reformulated Kalman gain can be expressed as
    \[
    \mathbf{K} = (\mathbf{H}^T \mathbf{R}^{-1} \mathbf{H} + \mathbf{P}^{-1})^{-1} \mathbf{H}^T \mathbf{R}^{-1},
    \]
    which reduces matrix inversion from $\mathcal{O}(m^3)$ to $\mathcal{O}(n^3)$ (with $n = \dim(\text{state}) \ll m$), directly tackling the \textit{computational bottleneck}.
\end{itemize}

We evaluate the implemented algorithm through ROS-based simulations and experiments on the public M3DGR dataset~\cite{m3dgr}, assessing performance in terms of estimation accuracy, computational latency, and robustness, and validating these results against theoretical analysis.

\subsection{Organization}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{media/workflow.pdf}
    \caption{Overview of the FAST-LIO estimation framework with IMU-LiDAR tight coupling, motion undistortion, and efficient Kalman update.}
    \label{fig:workflow}
\end{figure}

According to the workflow of the FAST-LIO framework (Fig. \ref{fig:workflow}), the remainder of this report is organized as follows: 
Section~\ref{sec:modeling} formally defines the state-space model of the IMU-LiDAR system; 
Section~\ref{sec:iekf} details the IEKF algorithm, including forward/backward propagation, residual computation, and iterative update; 
Section~\ref{sec:implementation} describes the simulation setup and implementation; 
Section~\ref{sec:results} presents quantitative results and performance analysis; 
and Section~\ref{sec:conclusion} concludes with contributions, limitations, and future work.
